{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"z/OS Utility","text":"<p>The z/OS Utility plug-in includes steps for retrieving and deploying IBM z/OS artifacts. It is installed and upgraded as part of the IBM UrbanCode Deploy server. This plugin will work with all the supported versions of UCD server/agents. There are some new features that are only supported if the agent is upgraded to those versions. If you attempt to use the feature that is not enabled for a version, process might fail with the message to upgrade the agent.</p> <p>This plug-in requires agents that run on the z/OS platform and works with z/OS component versions in UrbanCode Deploy. To learn how to create z/OS component versions in UrbanCode Deploy with data sets and HFS files on IBM z/OS, see Creating z/OS component versions.</p> <p>The plug-in includes steps that are related to deploying and rolling back data sets and HFS files, such as the following steps:</p> <ul> <li>Deploy Data Sets</li> <li>Rollback Data Sets</li> <li>Cleanup Backup Files</li> <li>Remove All Versions</li> <li>Remove Redundant Versions</li> <li>Generate Artifact Information</li> </ul> <p>The plug-in also includes steps that are related to running z/OS commands, submitting and tracking jobs, and working with data sets, such as the following steps:</p> <ul> <li>Submit Job</li> <li>Wait For Job</li> <li>Run TSO or ISPF Command</li> <li>Run MVS Command</li> <li>Allocate Data Set</li> <li>Copy Data Set</li> <li>Replace Tokens MVS</li> <li>Delete Datasets</li> </ul> <p>The Submit Job and Wait For Job steps require the job server component (JMON server) that is included with IBM UrbanCode Deploy, Rational Team Concert, or Rational Developer for System z. The Generate Artifact Information step scans version artifacts and generates text based on a template. The output text can be used as an input property to subsequent steps. Use the Generate Artifact Information step to batch-process data sets or members in a component version. You can also use the Generate Artifact Information step to select a subset of artifacts to process by applying filters on data set names, member names, deployment types, and custom properties.</p> <p>For more information and examples, see the Usage page in the plug-in documentation.</p>"},{"location":"downloads/","title":"Downloads","text":"<p>To download the plug-in, click the following version-specific links.</p> <ul> <li>ucd-zos-deploy-93.1170974.zip</li> <li>ucd-zos-deploy-92.1169106.zip</li> <li>ucd-zos-deploy-91.1168953.zip</li> <li>ucd-zos-deploy-91.1168861.zip</li> <li>ucd-zos-deploy-90.1167616.zip</li> <li>ucd-zos-deploy-90.1167272.zip</li> <li>ucd-zos-deploy-90.1166834.zip</li> <li>ucd-zos-deploy-89.1166068.zip</li> <li>ucd-zos-deploy-89.1165949.zip</li> <li>ucd-zos-deploy-88.1165251.zip</li> <li>ucd-zos-deploy-88.1165235.zip</li> <li>ucd-zos-deploy-88.1165026.zip</li> <li>ucd-zos-deploy-88.1164921.zip</li> <li>ucd-zos-deploy-87.1164411.zip</li> <li>ucd-zos-deploy-86.1162422.zip</li> <li>ucd-zos-deploy-85.1159123.zip</li> <li>ucd-zos-deploy-84.1158587.zip</li> <li>ucd-zos-deploy-84.1158288.zip</li> <li>ucd-zos-deploy-84.1158243.zip</li> <li>ucd-zos-deploy-83.1157845.zip</li> <li>ucd-zos-deploy-83.1156667.zip</li> <li>ucd-zos-deploy-83.1155867.zip</li> <li>ucd-zos-deploy-82.1155820.zip</li> <li>ucd-zos-deploy-81.1155387.zip</li> <li>ucd-zos-deploy-80.1155287.zip</li> <li>ucd-zos-deploy-79.1153131.zip</li> <li>ucd-zos-deploy-78.1151227.zip</li> <li>ucd-zos-deploy-78.1150737.zip</li> <li>ucd-zos-deploy-77.1150109.zip</li> <li>ucd-zos-deploy-77.1149658.zip</li> <li>ucd-zos-deploy-76.1149370.zip</li> <li>ucd-zos-deploy-76.1149314.zip</li> <li>ucd-zos-deploy-75.1142510.zip</li> <li>ucd-zos-deploy-74.1140702.zip</li> <li>ucd-zos-deploy-74.1139650.zip</li> <li>ucd-zos-deploy-73.1138577.zip</li> <li>ucd-zos-deploy-72.1138404.zip</li> <li>ucd-zos-deploy-72.1134247.zip</li> <li>ucd-zos-deploy-71.1132900.zip</li> <li>ucd-zos-deploy-71.1132832.zip</li> <li>ucd-zos-deploy-70.1132810.zip</li> <li>ucd-zos-deploy-70.1132678.zip</li> <li>ucd-zos-deploy-69.1132511.zip</li> <li>ucd-zos-deploy-68.1132402.zip</li> <li>ucd-zos-deploy-68.1132343.zip</li> <li>ucd-zos-deploy-68.1131557.zip</li> <li>ucd-zos-deploy-67.1131158.zip</li> <li>ucd-zos-deploy-66.1130920.zip</li> <li>ucd-zos-deploy-65.1130883.zip</li> <li>ucd-zos-deploy-64.1128758.zip</li> <li>zos-deploy-63.1127790.zip</li> <li>zos-deploy-63.1127788.zip</li> <li>zos-deploy-63.1127595.zip</li> <li>zos-deploy-63.1127569.zip</li> <li>zos-deploy-63.1127397.zip</li> <li>zos-deploy-63.1127191.zip</li> <li>zos-deploy-63.1127063.zip</li> <li>zos-deploy-62.1127045.zip</li> <li>zos-deploy-61.1126994.zip</li> <li>zos-deploy-60.1126884.zip</li> <li>zos-deploy-60.1126867.zip</li> <li>zos-deploy-59.1126010.zip</li> <li>zos-deploy-59.1125740.zip</li> <li>zos-deploy-59.1125359.zip</li> <li>zos-deploy-59.1125062.zip</li> <li>zos-deploy-59.1125008.zip</li> <li>zos-deploy-58.1122539.zip</li> <li>zos-deploy-57.1121803.zip</li> <li>zos-deploy-57.1121798.zip</li> <li>zos-deploy-57.1121666.zip</li> <li>zos-deploy-56.1102074.zip</li> <li>zos-deploy-56.1100633.zip</li> <li>zos-deploy-56.1098848.zip</li> <li>zos-deploy-56.1079646.zip</li> <li>zos-deploy-56.1078621.zip</li> <li>zos-deploy-55.1074381.zip</li> <li>zos-deploy-54.1072366.zip</li> <li>zos-deploy-54.1071719.zip</li> <li>zos-deploy-54.1071464.zip</li> <li>zos-deploy-53.1061868.zip</li> <li>zos-deploy-53.1059252.zip</li> <li>zos-deploy-53.1058652.zip</li> <li>zos-deploy-52.1058003.zip</li> <li>zos-deploy-52.1056715.zip</li> <li>zos-deploy-51.1051969.zip</li> <li>zos-deploy-51.1050698.zip</li> <li>zos-deploy-51.1049476.zip</li> <li>zos-deploy-51.1044191.zip</li> <li>zos-deploy-50.1041523.zip</li> <li>zos-deploy-49.1039701.zip</li> <li>zos-deploy-48.1036702.zip</li> <li>zos-deploy-48.1036113.zip</li> <li>zos-deploy-46.1034395.zip</li> <li>zos-deploy-45.1026879.zip</li> <li>zos-deploy-44.1024758.zip</li> <li>zos-deploy-41.1011241.zip</li> <li>zos-deploy-39.1001623.zip</li> <li>zos-deploy-39.992980.zip</li> <li>zos-deploy-38.981263.zip</li> <li>zos-deploy-32.972888.zip</li> <li>zos-deploy-31.945624.zip</li> <li>zos-deploy-30.931134.zip</li> <li>zos-deploy-28.896105.zip</li> <li>zos-deploy-27.864857.zip</li> <li>zos-deploy-26.813109.zip</li> <li>zos-deploy-24.800369.zip</li> <li>zos-deploy-22.787240.zip</li> <li>zos-deploy-22.786876.zip</li> </ul>"},{"location":"overview/","title":"Overview","text":"<p>The z/OS Utility plug-in includes steps for retrieving and deploying IBM z/OS artifacts.</p> <p>This plug-in requires agents that run on the z/OS platform. The Submit Job and Wait For Job steps require the job server component that is included with IBM UrbanCode Deploy, Rational Team Concert, or Rational Developer for System z.</p> <p>The plug-in includes steps that are related to deploying z/OS artifacts, such as the following steps:</p> <ul> <li>Copy Artifacts</li> <li>FTP Artifacts</li> <li>Deploy Data Sets</li> <li>Rollback Data Sets</li> <li>Cleanup Backup Files</li> </ul> <p>The plug-in also includes steps that are related to running z/OS commands, submitting and tracking jobs, and working with data sets, such as the following steps:</p> <ul> <li>Submit Job</li> <li>Wait For Job</li> <li>Run TSO or ISPF Command</li> <li>Run MVS Command</li> <li>Allocate Data Set</li> <li>Copy Data Set</li> <li>Replace Tokens MVS</li> </ul> <p>To learn how to import components from data sets in IBM z/OS, see Deploying to the z/OS platform.</p> <p>The plug-in also includes the Generate Artifact Information step, which scans version artifacts and generates text based on a template. The output text can be used as an input property for subsequent steps. Use the Generate Artifact Information to process data sets or members in a component version. You can also use the Generate Artifact Information step to select a set of artifacts to process, by applying filters on data set names, member names, deployment types, and custom properties.</p> <p>The plug-in also includes steps that are related to managing redundant incremental versions, such as the following steps:</p> <ul> <li>Remove All Versions</li> <li>Remove Redundant Versions</li> </ul>"},{"location":"overview/#compatibility","title":"Compatibility","text":"<ul> <li>IBM UrbanCode Deploy version 7.0.0 or later</li> <li>IBM UrbanCode Deploy agents on z/OS</li> <li>IBM z/OS version 2.4 or later with System REXX</li> <li>Starting with version 49 this plug-in requires Java 8 or above</li> </ul>"},{"location":"overview/#installation","title":"Installation","text":"<p>No special steps are required for installation. See Installing plug-ins in UrbanCode products. You must install and configure the z/OS deployment tools before you use the plug-in. To learn how to install and configure the z/OS deployment tools, see Deploying to the z/OS platform. You must configure the job server component before you run the following steps: Submit Job and Wait For Job.</p>"},{"location":"overview/#history","title":"History","text":""},{"location":"overview/#version-93","title":"Version 93","text":"<ul> <li>Removed input to pass binder shared library path from Deploy datasets step</li> <li>Added option to pass retain days in Remove All Versions and Remove Redundant Versions steps</li> <li>Dependent groovy libraries are now shipped with plugin to avoid incompatibility issues as groovy versions differ by agent version.</li> <li>Performance improvements.</li> </ul>"},{"location":"overview/#version-92","title":"Version 92","text":"<ul> <li>Minor improvements in Runtime delta deployment</li> <li>Binder Path input is optional in Deploy Data sets step</li> </ul>"},{"location":"overview/#version-91","title":"Version 91","text":"<ul> <li>Added support for single source to multiple targets mapping</li> <li>Improvements in ISPF gateway error handling</li> <li>User can set MAX-RC for copy dataset step</li> <li>Improvements in HFS Deployment</li> <li>Fixed PH62152 - RcException while allocating temporary datasets</li> </ul>"},{"location":"overview/#version-90","title":"Version 90","text":"<ul> <li>Inventory Delta-deploy is now timezone agnostic</li> <li>Minor code improvements </li> <li>PH60517 - Inventory Delta deploy discards the number of HLQ set in component configuration during artifact comparison</li> <li>Fixed bug with Rollback when two or more source PDS mapped to same target during deployment</li> <li>Rollback Program ported from Groovy to Java</li> <li>Dataset Mapping that have DUMMY as target containers are not checked for R/W access</li> </ul>"},{"location":"overview/#version-89","title":"Version 89","text":"<ul> <li>Added new input to TSO/ISPF step to pass temporary DSN prefix</li> <li>Removed ibmjzos jar from the plugin as it is shipped with IBM Java for z/OS</li> <li>Fixed PH59773 - Deploy data sets step does not skip backup when the latest version is deployed again</li> </ul>"},{"location":"overview/#version-88","title":"Version 88","text":"<ul> <li>Fixed PH57595 - ROLLBACK DATASET STEP DELETES PDS AFTER DELETING ALL THE NEWLY CREATED MEMBERS DURING DEPLOYMENT</li> <li>Minor improvements</li> <li>Huge improvements in Rollback Manifest XML file generated during deploy data sets step with backup enabled</li> <li>Fixed APAR PH57385 - Error deploying version.Status code - 400</li> <li>Exit Restore Backup step with a warning when there is no datasets backup</li> </ul>"},{"location":"overview/#version-87","title":"Version 87","text":"<ul> <li>Added new plugin step - Restore Backup Datasets</li> <li>Use Legacy ISPF Gateway to run programs by default</li> <li>Fixed NoSuchMethodError during HFS deployment</li> <li>Improvements in Submit Job and Wait For Job steps.   Note: As part of the improvement, the order of authentication method is changed to below</li> <li>Use Agent/Impersonation Id</li> <li>Use PassTicket</li> <li>Use Password</li> </ul>"},{"location":"overview/#version-86","title":"Version 86","text":"<ul> <li>Removed support for Submit Job and Wait For Job steps to run outside the mainframe systems</li> <li>Fixed APAR PH57188 - SUBMIT JOB INCORRECT FORMATTING WHEN JCL LINE EXCEEDS 72 CHARACTERS</li> </ul>"},{"location":"overview/#version-85","title":"Version 85","text":"<ul> <li>Minor improvements in New Package Format Deployment and Deleting Datasets</li> <li>Added input to pass Ispf Gateway Path for Deploy Data sets step</li> </ul>"},{"location":"overview/#version-84","title":"Version 84","text":"<ul> <li>Fixes output buffering issue when TSO/ISPF command prints too much output.</li> <li>Added deployment action filter and new loop type to exclude Deleted missing PDS members</li> <li>Fixed a typo with deploy type in generate artifact info step</li> <li>Added check for Target Dataset Filter to allow only dataset or member loop types</li> </ul>"},{"location":"overview/#version-83","title":"Version 83","text":"<ul> <li>Added new input to enable or disable PDS member replace during deployment</li> <li>Fixed issue with cleanup</li> <li>Fixed Null Pointer Exception in Generate Artifact information step</li> </ul>"},{"location":"overview/#version-82","title":"Version 82","text":"<ul> <li>Fixes CVE-2023-1436 and APAR PH53341 </li> </ul>"},{"location":"overview/#version-81","title":"Version 81","text":"<ul> <li>Fixed APAR PH53341 related to parsing error when deploying zOS versions</li> </ul>"},{"location":"overview/#version-80","title":"Version 80","text":"<ul> <li>Fixed issue with agent version check and minor improvements</li> </ul>"},{"location":"overview/#version-79","title":"Version 79","text":"<ul> <li>Updates deployed artifacts to ZInventory when run on agent versions above 730 </li> </ul>"},{"location":"overview/#version-78","title":"Version 78","text":"<ul> <li>Fixes vulnerability CVE-2022-45693 and CVE-2022-45685</li> <li>Fixed JMON issue -   BUZ300E Internal error: Unknown client protocol level.   FEJ300E Internal error: Unknown client protocol level.</li> </ul>"},{"location":"overview/#version-77","title":"Version 77","text":"<ul> <li>Minor improvements</li> <li>Fixed issue with deleted containers for generating artifact information</li> </ul>"},{"location":"overview/#version-76","title":"Version 76","text":"<ul> <li>Support for deleting members from PDS which is in contention</li> <li>Fixes vulnerability CVE-2021-37533</li> </ul>"},{"location":"overview/#version-75","title":"Version 75","text":"<ul> <li>Updating jettison library for CVE-2022-40150 CVE-2022-40149</li> </ul>"},{"location":"overview/#version-74","title":"Version 74","text":"<ul> <li>Added new step to clean-up backup files </li> </ul>"},{"location":"overview/#version-73","title":"Version 73","text":"<ul> <li>Fixed issue with replacing token for each job and minor improvements</li> </ul>"},{"location":"overview/#version-72","title":"Version 72","text":"<ul> <li>Added support for deleting multiple datasets using Delete dataset step</li> <li>Fixed security issue CVE-2021-29425</li> </ul>"},{"location":"overview/#version-71","title":"Version 71","text":"<ul> <li>TSO ISPF command and FTP Artifacts step migrated to Java</li> <li>PH46505 Fixed issue with filtering containers mapped to same Target PDS in Generate Artifact step</li> </ul>"},{"location":"overview/#version-70","title":"Version 70","text":"<ul> <li>Wait For Job and MVS Command steps are migrated to Java</li> <li>Fixed issue with Java 11 to run shell script</li> </ul>"},{"location":"overview/#version-69","title":"Version 69","text":"<ul> <li>Added new step to delete dataset/PDS members</li> </ul>"},{"location":"overview/#version-68","title":"Version 68","text":"<ul> <li>Update udclient and uDeployRestClient</li> <li>Fixed issue with GDG version creation in Allocate Steps</li> </ul>"},{"location":"overview/#version-67","title":"Version 67","text":"<ul> <li>Minor improvements.</li> </ul>"},{"location":"overview/#version-66","title":"Version 66","text":"<ul> <li>Remove All Versions and Remove Redundant Versions steps are migrated to run on Java for performance improvements.</li> <li>Added checkbox for Dry run in Remove All Versions step.</li> </ul>"},{"location":"overview/#version-65","title":"Version 65","text":"<ul> <li>Copy Artifacts and Copy Data Set steps are migrated to run on Java for performance improvements.</li> </ul>"},{"location":"overview/#version-64","title":"Version 64","text":"<ul> <li>Remove log4j functionality related to: CVE-2019-17571, CVE-2020-9488. CVE-2021-4104, CVE-2022-23302, CVE-2022-23305, CVE-2022-23307</li> </ul>"},{"location":"overview/#version-63","title":"Version 63","text":"<ul> <li>Minor enhancements in Submit Job and Wait For Job steps</li> <li>Fixed handling of temporary datasets in case of failure in new package format</li> <li>Minor Improvments in new package format</li> <li>Fixed ZFileException while cleaning up unclosed temporary dataset</li> <li>Fixed IGD17036I in new package deployments</li> </ul>"},{"location":"overview/#version-62","title":"Version 62","text":"<ul> <li>Added check box to delete dataset if already exist for Allocate steps</li> </ul>"},{"location":"overview/#version-61","title":"Version 61","text":"<ul> <li>Allocate data set steps are rewritten in Java for better performance</li> </ul>"},{"location":"overview/#version-60","title":"Version 60","text":"<ul> <li>Enhancements and bug fixes for HFS deployment and rollback \u2013 APAR PH42431</li> </ul>"},{"location":"overview/#version-591126010","title":"Version 59.1126010","text":"<ul> <li>Fixed HFS untar issue for Ant version upgrade</li> </ul>"},{"location":"overview/#version-591125740","title":"Version 59.1125740","text":"<ul> <li>Fixed APAR-PH41930 Parsing return codes from ISPF gateway has been enhanced</li> </ul>"},{"location":"overview/#version-591125359","title":"Version 59.1125359","text":"<ul> <li>Fixed Page End statement in submit job step to display after output</li> </ul>"},{"location":"overview/#version-591125062","title":"Version 59.1125062","text":"<ul> <li>Fixed APAR PH41991 added support for JOBRC parameter in submit job step</li> </ul>"},{"location":"overview/#version-591125008","title":"Version 59.1125008","text":"<ul> <li>Changed Prevent Risky Rollback input in Rollback step from check-box to Drop-Down</li> </ul>"},{"location":"overview/#version-581122539","title":"Version 58.1122539","text":"<ul> <li>Added support to run Wait For Job step using Agent Id or Impersonation Id</li> </ul>"},{"location":"overview/#version-571121803","title":"Version 57.1121803","text":"<ul> <li>Reformatted checkaccess error message</li> </ul>"},{"location":"overview/#version-571121798","title":"Version 57.1121798","text":"<ul> <li>Fixed PH39119 \u2013 Rollback step failing with version not deployed error after a failed deployment</li> </ul>"},{"location":"overview/#version-571121666","title":"Version 57.1121666","text":"<ul> <li>Added support for submitting job using Agent Id or Impersonation Id</li> </ul>"},{"location":"overview/#version-561102074","title":"Version 56.1102074","text":"<ul> <li>Fixed newline character parsing in Generate artifact template input</li> </ul>"},{"location":"overview/#version-561100633","title":"Version 56.1100633","text":"<ul> <li>Fixed PH35042 \u2013 Fixed Array index Out Of Bound failure</li> </ul>"},{"location":"overview/#version-561098848","title":"Version 56.1098848","text":"<ul> <li>Fixed PH34874 \u2013 Fixed the issue of ISPF command executions reported as success when it is a failure</li> </ul>"},{"location":"overview/#version-56","title":"Version 56","text":"<ul> <li>Deploy datasets \u2013 now accepts DUMMY in pdsmapping target.</li> <li>Input in pds mapping field can be of the format src.dataset,DUMMY</li> </ul>"},{"location":"overview/#version-55","title":"Version 55","text":"<ul> <li>Added hidden input to pass Binder API Path for RUNTIME delta deployment to add to LIBPATH. (APAR PH31349)</li> <li>Added check box to print debug logs for Deploy and Rollback steps</li> <li>Added check box to print each job output in a new page in submit job plugin step (Needs Java 8)</li> </ul>"},{"location":"overview/#version-54","title":"Version 54","text":"<ul> <li>Ported following steps to run from a non-zOS agent as well</li> <li>Submit job</li> <li>Wait for job</li> <li>Moved FTP plugin step into a new plugin ( https://urbancode.github.io/IBM-UCx-PLUGIN-DOCS/UCD/zos-ftp/ )</li> <li>Added permission checks for ISPF work directory and file</li> <li>Fixed incompatible code with Java 7 (Earlier versions of this plugin required Java 8. Based on a request, we ported the plugins to run with Java 7 &amp; 8 as well.</li> <li>Enhancement on runtime delta deployment</li> <li>Fixed exception for HFS deployment and Rollback with new Ant version (That was introduced in UCD 7.1.0.1)</li> <li>Minor bug fixes in HFS deployment / Rollback operations</li> </ul>"},{"location":"overview/#version-53","title":"Version 53","text":"<ul> <li>Enhancement for Partial Deployment based on Container Filter</li> <li>Fixed exception for HFS Deployment with previous HFS version (PH27636)</li> </ul>"},{"location":"overview/#version-52","title":"Version 52","text":"<ul> <li>PH24188 \u2013 Fixed deployment freeze for large component version</li> <li>Support for copyTypes with package format v2</li> <li>Enhancement to ignore unresolved properties in generate artifacts information step</li> </ul>"},{"location":"overview/#note-from-version-51-groovy-string-methods-are-not-interpreted-in-template-input-since-the-code-is-rewritten-in-java","title":"Note: From version 51, groovy string methods are not interpreted in Template input since the code is rewritten in Java.","text":""},{"location":"overview/#version-51","title":"Version 51","text":"<ul> <li>Rewriting Generate Version Artifact Information groovy program in Java.</li> <li>Fixed null pointer exception error when deployType filter is applied to resource with no deployType</li> <li>Fixed null pointer exception error when regular expression is used in deployType</li> <li>PH23624 \u2013 Fixed NoClassDef error for submit job step using passcode authentication</li> </ul>"},{"location":"overview/#version-50","title":"Version 50","text":"<ul> <li>Rewriting Replace Tokens MVS plugin from Groovy to Java for performance improvement</li> </ul>"},{"location":"overview/#version-49","title":"Version 49","text":"<ul> <li>Submit Job groovy plugin rewritten in Java</li> <li>Added functionality to delete all contents in the target HFS folder and then deploy the artifacts from UCD version</li> <li>Added functionality to determine the toolkit version and call appropriate methods and fixed an issue with rollback for deleted HFS files</li> <li>Required Java 8 or above from this plugin version</li> </ul>"},{"location":"overview/#version-48","title":"Version 48","text":"<ul> <li>PH11769- Fix for replace tokens with EAV VTOC volumes &amp; improved performance for new package format</li> </ul>"},{"location":"overview/#version-46","title":"Version 46","text":"<ul> <li>Added functionality for the new package format deploy</li> </ul>"},{"location":"overview/#version-45","title":"Version 45","text":"<ul> <li>Fixing CVE:CVE-2019-4233</li> </ul>"},{"location":"overview/#version-44","title":"Version 44","text":"<ul> <li>Allowing mutiple source and multiple target directories to deploy instead of one HFS Target directory. NOTE: UrbanCode Deploy server 7.0.3 and the same level of the agent are required for using this HFS feature.</li> </ul>"},{"location":"overview/#version-41","title":"Version 41","text":"<ul> <li>Updated Deploy Data Sets step to support runtime delta deploy. NOTE: UrbanCode Deploy server 7.0.2 and the same level of the agent is required for using this runtime delta deploy feature.</li> </ul>"},{"location":"overview/#version-391001623","title":"Version 39.1001623","text":"<ul> <li>PH03567 To fix the issue of environment properties getting trimmed in Replace Tokens MVS step</li> <li>PH03684 To fix the issue when a REXX/ISPF process that gives out more than 2000+ lines are run from UCD, the response never comes back to the server</li> </ul>"},{"location":"overview/#version-39992980","title":"Version 39.992980","text":"<ul> <li>PH01955 Fixed the issue with deploy datasets failing when we use * with an add and delete of same PDS</li> <li>PH01081 Fixed the issue with class not found for JES logger</li> </ul>"},{"location":"overview/#version-27864857","title":"Version 27.864857","text":"<p>Added support for encrypted input and output properties. Updated Replace Tokens MVS step to preserve ISPF statistics. Fixed bugs.</p>"},{"location":"overview/#version-26813109","title":"Version 26.813109","text":"<p>Updated Generate Artifact Information step to support order by.</p>"},{"location":"overview/#version-24800369","title":"Version 24.800369","text":"<p>Version 24 includes the following updates:</p> <ul> <li>A fix for a problem that is related to replacing tokens in VB data sets.</li> <li>The Rollback Data Sets step was updated to prevent risky rollbacks.</li> </ul>"},{"location":"overview/#version-22787240","title":"Version 22.787240","text":"<p>Fixes APAR PI57417. Plug-in now checks the agent settings for acceptance of self-signed certificates.</p>"},{"location":"overview/#version-17692574","title":"Version 17.692574","text":"<p>This release includes the following updates:</p> <ul> <li>A fix for an issue where the deployment data set and rollback data set unnecessarily requires data set ALTER privilege.</li> <li>The Generate Artifact Information step now supports sequential data sets and data set deletion.</li> <li>The Generate Artifact Information step now includes an option to mark the step as failed when no result is generated.</li> <li>A count output property now stores the number of artifacts generated.</li> <li>The Replace Tokens MVS step now allows updates to a data set that is opened by other readers. The step uses DISP=SHR to open the data set for output.</li> <li>The Submit Job step now supports a default job statement.</li> <li>Updated help for steps.</li> <li>A fix for an issue where the Submit Job step did not use PassTicket authentication.</li> </ul>"},{"location":"steps/","title":"Steps","text":"<ul> <li>Allocate Data Set</li> <li>Allocate Data Set From Existing</li> <li>Allocate SMS Managed Data Set</li> <li>Copy Artifacts</li> <li>Copy Data Set</li> <li>Deploy Data Sets</li> <li>FTP Artifacts</li> <li>Generate Artifact Information</li> <li>Remove All Versions</li> <li>Remove Redundant Versions</li> <li>Replace Tokens MVS</li> <li>Rollback Data Sets</li> <li>Run MVS Command</li> <li>Run TSO or ISPF Command</li> <li>Submit Job</li> <li>Wait For Job</li> <li>Delete Dataset</li> <li>Cleanup Backup Files</li> <li>Restore Backup Datasets</li> </ul>"},{"location":"steps/#allocate-data-set","title":"Allocate Data Set","text":"<p>Allocate a non-SMS-managed data set. Note: To create a GDG version add (+1) along with GDG base. An output property DatasetName will contain the actual GDG version dataset name that is created and can be referred in successive steps of the process.</p> Name Type Description Required Average Record Unit Enumeration: K/M/U/--- Select the unit to use when allocating average record length. U specifies single-record units (bytes). K specifies thousand-record units (kilobytes). M specifies million-record units (megabytes). (---) specifies the system default value. No Block Size String Specify the number of bytes of data to place in each block, based on the record length. Yes Data Set Name String Data set name. If the single quotation marks are omitted, the users data set prefix from the TSO profile is automatically appended to the front of the data set name. Yes Data Set Name Type Enumeration: LIBRARY/PDS LIBRARY, PDS or Default() No Delete Existing Data Set Boolean Select to delete dataset if already exist before allocation. No Directory Blocks String The number of directory blocks to allocate. Specify zero for a sequential data set. Specifying LIBRARY in the data set name might override a setting of zero directory blocks. No Primary Quantity String Specify the primary quantity in average record units. Yes Record Format Enumeration: F,B/F/V,B/V/U/F,B,A/V,B,A/F,B,M/F,M/V,B,M/V,M No Record Length String Yes Secondary Quantity String Specify the secondary quantity in average record units. Yes Space Units Enumeration: BLKS/TRACKS/CYLINDERS BLKS, TRKS, CYLS Yes Volume Serial String Leave blank to use the system default volume. No"},{"location":"steps/#allocate-data-set-from-existing","title":"Allocate Data Set From Existing","text":"<p>Create a data set with the attributes of an existing model data set. Note: To create a GDG version add (+1) along with GDG base. An output property DatasetName will contain the actual GDG version dataset name that is created and can be referred in successive steps of the process.</p> Name Type Description Required Data Set Name String Data set name. If the single quotation marks are omitted, the users data set prefix from the TSO profile is automatically appended to the front of the data set name. Yes Delete Existing Data Set Boolean Select to delete dataset if already exist before allocation. No Like String Specify the name of an existing data set to use as a model. The attributes of this data set are used as the attributes for the data set being allocated. If the single quotation marks are omitted, the users data set prefix from the TSO profile is automatically appended to the front of the data set name. Yes Primary Quantity String Specify the primary quantity in space units. No Secondary Quantity String Specify the secondary quantity in space units. No Space Units Enumeration: \u2014/BLKS/TRACKS/CYLINDERS BLKS, TRKS, CYLS or default() No Volume Serial String Leave blank to use the system default volume. No"},{"location":"steps/#allocate-sms-managed-data-set","title":"Allocate SMS Managed Data Set","text":"<p>Allocate an SMS-managed data set. Note: To create a GDG version add (+1) along with GDG base. An output property DatasetName will contain the actual GDG version dataset name that is created and can be referred in successive steps of the process.</p> Name Type Description Required Data Class String Leave blank to use the default data class. No Data Set Name String Data set name. If the single quotation marks are omitted, the users data set prefix from the TSO profile is automatically appended to the front of the data set name. Yes Delete Existing Data Set Boolean Select to delete dataset if already exist before allocation. No Management Class String Leave blank to use the default management class. No Storage Class String Leave blank to use the default storage class. No"},{"location":"steps/#copy-artifacts","title":"Copy Artifacts","text":"<p>Load artifacts from a local repository.</p> Name Type Description Required Directory Offset String The working directory to use when running the command. This directory is relative to the current working directory. Yes"},{"location":"steps/#copy-data-set","title":"Copy Data Set","text":"<p>Copy a data set.</p> Name Type Description Required Exclude Members String Specify a list of members in the source PDS to skip when copying. Separate member names with newline characters. No From PDS String Specify the names of the source PDS, separated by newline characters. Use the following format: PDS-NAME (or) PDS-NAME,R. R specifies that all members of the source PDS replace any members with the same name in the target PDS. Yes Include Members String Specify the members in the source PDS to copy, separated by newline characters. Use the following format: MEMBER-NAME (or) MEMBER-NAME, NEW-MEMBER-NAME[, R] (or) MEMBER-NAME,,R. To rename a member, specify the current name of the member, followed by the new name and optionally the R (replace) parameter. To replace a member, specify the name of the member and the R parameter, separated by two commas. No Load Module Dataset Boolean Select to use the IEBCOPY COPYMOD control statement when copying load modules. No To PDS String Specify the name of the target PDS. Yes"},{"location":"steps/#deploy-data-sets","title":"Deploy Data Sets","text":"<p>Deploy data sets and HFS files</p> Name Type Description Required Allow Creating Data Set String Specify TRUE to create a data set if the specified target data set does not exist. No Allow Creating Directory String Specify TRUE to create the directory if the specified HFS target directory does not exist. No Backup for Rollback Boolean Select to create a backup of the data sets and files which are going to be replaced. A backup must exist to do rollback. No Check Access Boolean Select to check permission to update the data sets to deploy. No Container Filter String The filter to limit Source datasets to be deployed. Java regular expression matching is used if the filter starts and ends with a forward slash (/). For example, specify <code>/.*LOAD/</code> to match any data set containers ending with LOAD. If the filter is not a regular expression, exact matching is used. Separate each filter with a newline character. No Data Set Mapping String Specify a list of mapping rules for the data set packages, separated by newline characters. Use the following format: Source_Data_Set,Target_Data_Set. Use the asterisk (*) in the Source_Data_Set value to match any characters. Specify the same Source_Data_Set value and map it with different target datasets to deploy the same Source_Data_Set artifacts to multiple target datasets. Use Source_Data_Set,DUMMY mapping to skip backup/deployment for a particular dataset. It will show as deployed at the environment level, but in actuality, the backup/deployment is skipped. No Delete the Target Directory contents Boolean Select to delete all contents in the target folder and then deploy the artifacts from the selected version. Backup of the target directory will not be taken if this is set. Either the checkbox \u2018Delete the Target Directory contents\u2019 should be selected or the checkbox \u2018Backup for Rollback\u2019 checkbox should be selected. No Delta Deploy Enumeration: FULL/INVENTORY/RUNTIME/<code>${p?:delta.deploy.value}</code> Specify FULL deployment type to replace all artifacts with artifacts in the current component version. Specify INVENTORY deployment type, a delta deployment, to reduce the deployment time significantly by deploying only the changes between artifacts. The comparison is based on identity attributes including lastModifiedTimestamp and customer properties starting with SYS.id. Specify RUNTIME deployment type, a delta deployment, to use checksum logic to compare artifacts to be deployed with the same artifacts in the target environment. This check is done for every artifact. Only artifacts with checksums that don\u2019t match are considered as changed and used for deployment.Note:* Two artifacts are considered the same when at least one attribute can be used for comparison and all attributes that are used for comparison match exactly. The attributes used for delta deployment type are explained in the table below. Yes HFS Directory mappings String Specify target directory mappings to deploy HFS files. It can be either be a single target directory or mapping similar to PDS mapping with source and target directories. No Replace PDS Member Enumeration: TRUE/FALSE/<code>${p?:deploy.env.replace.pds.member}</code> Specify TRUE to replace PDS member in target if exist. Setting to FALSE will run deployment only if all PDS members to be deployed do not exist. Yes Hidden Properties (below) ISPF Gateway Path String Specify the path for ISPF gateway binary files. Yes Deployment Base Path String The base location to store deployment results and backups for rollback. The default value is the BUZ_DEPLOY_BASE environment variable, which is set to the deployment base path that was specified during installation. Typically, you do not change this value. Yes Temporary DSN Prefix String Specify a DSN prefix to be used to create temporary data sets. The default value is the BUZ_TMP_DSN_PREFIX environment variable. If a value is not provided, the prefix in the agent user\u2019s profile or the agent user\u2019s ID is used. Prefix should not be more than 17 characters. No Is Merged Version String Specify true if this is a merged version. No Version Name String Version Name Yes Version Id String Version Id Yes Version Type String Version Type Yes Component Name String Component Name Yes Resource Id String Resource Id Yes Component Id String Component Id Yes <p>For each artifact in a delta deployment, the following attributes are compared to the latest inventory version of the same artifact.</p> Parameter Where Used Description Last Modified Timestamp INVENTORY IBM UrbanCode Deploy reads the Last Modified Timestamp value when the version is packaged. All load modules that are build by RTC have Last Modified Timestamp values stored in SSI. If SSI has no Last Modified Timestamp values, ZLM4DATE, ZLMTIME and ZLMSEC statistical values are read from ISPF. Note that the JCL-built or third-party tool load modules have a Last Modified Timestamp value of NO. Custom properties starting with SYS.id (aka identification properties) INVENTORY These properties provide an open framework for the customer or provider to add additional attributes to indicate whether two artifacts are the same. Two artifacts are considered the same when all attributes that are used for comparison match exactly. checksum RUNTIME The checksum value is determined when the version is packaged. During a RUNTIME deployment, the checksum is calculated for the artifact in the target environment and compared with the checksum calculated during the version creation. These properties can be hash or binder information for load modules. <ul> <li>To prevent adding inputs data to Z Inventory table follow Disable inputs for Z Inventory.    This will keep the size of the Z Inventory table in check.</li> </ul>"},{"location":"steps/#ftp-artifacts","title":"FTP Artifacts","text":"<p>Load artifacts from a remote repository using FTP.</p> Name Type Description Required Directory Offset String The working directory to use when running the command. This directory is relative to the current working directory. Yes"},{"location":"steps/#generate-artifact-information","title":"Generate Artifact Information","text":"<p>Generate text information for selected version artifacts. The information is sent to the text output property for use by later steps. Note: From version 51, groovy string methods are not interpreted in Template input since the code is rewritten in Java. Use our new plugin https://urbancode.github.io/IBM-UCx-PLUGIN-DOCS/UCD/zos-multi-generate-artifact-info/ to generate multiple templates using a single step</p> Name Type Description Required Container Name Filter String Specify a filter to use on the container name. The container can be data set, directory, or generic artifact group. Java regular expression matching is used if the filter starts and ends with a forward slash (/). For example, specify /.*LOAD/ to match any text that ends with LOAD. If the filter is not a regular expression, exact matching is used. No Custom Properties Filter String Specify a list of custom properties filters, separated by newline characters. Use the following format: propertyName=valueFilter. A property without valueFilter selects all artifacts that have that property. Java regular expression matching is used if the filter starts and ends with a forward slash (/). For example, specify developer=/M.*/ to match artifacts with a developer property where the value of the property starts with M. If valueFilter is not a regular expression, exact matching is used. For example, developer=Martin matches artifacts where the value of the developer property is Martin. No Deploy Type Filter String Specify a filter to use on the deploy type. Java regular expression matching is used if the filter starts and ends with a forward slash (/). For example, specify /.*LOAD/ to match any text that ends with LOAD. If the filter is not a regular expression, exact matching is used. No Fail On Empty Boolean Select to set the step to fail if no text is generated. No Ignore unresolved properties Boolean Check this box to ignore unresolved properties in the template. On Default(unchecked) this step will fail if any unresolved properties are found. No For Each Enumeration:1) Member2) PDS3) Sequential4) DeletedMember5) DeletedPDS6) DeletedSequential7) Directory8) File9) DeletedFile10) GenericArtifactGroup11) GenericArtifact12) Deleted PDS Member - Exclude missing members Generate information for each artifact of the selected type. Yes Order By Enumeration:ASCDESCSHIPLIST Yes Resource Name Filter String Specify a filter to use on the resource name. The resource can be data set member, file, or generic artifact. Java regular expression matching is used if the filter starts and ends with a forward slash (/). For example, specify /.*LOAD/ to match any text that ends with LOAD. If the filter is not a regular expression, exact matching is used. No Target Data Set Name Filter String Specify a filter to use on the target data set name. Java regular expression matching is used if the filter starts and ends with a forward slash (/). For example, specify /.*LOAD/ to match any text that ends with LOAD. If the filter is not a regular expression, exact matching is used. No Template String Specify the template to use to generate text. The text output property contains the generated text from this step. Subsequent steps can access this text with the<code>${p:stepName/text}</code> property. Add separators, including line breaks, in the template as needed. Use <code>${propname}</code> to access custom properties. The following built-in properties are available: <code>${sourceDataset}</code> for the source dataset name. <code>${dataset}</code> for the target dataset name. <code>${member}</code> for the member name. <code>${deployType}</code> for the deployment type. <code>${artifactGroup}</code> for the generic artifact group name. <code>${artifact}</code> for the generic artifact name. <code>${directory}</code> for the directory name. <code>${file}</code> for the file name. <code>${inputsUrl}</code> for the url of the inputs. All property names are case-sensitive. Do not use the built-in names for custom properties. Yes Deployment Action Filter Enumeration:${p?:artifact.deployment.action}&lt;br/CREATEDUPDATED Specify the template to use to generate text. The text output property contains the generated text from this step. Subsequent steps can access this text with the<code>${p:stepName/text}</code> property. Add separators, including line breaks, in the template as needed. Use <code>${propname}</code> to access custom properties. The following built-in properties are available: <code>${sourceDataset}</code> for the source dataset name. <code>${dataset}</code> for the target dataset name. <code>${member}</code> for the member name. <code>${deployType}</code> for the deployment type. <code>${artifactGroup}</code> for the generic artifact group name. <code>${artifact}</code> for the generic artifact name. <code>${directory}</code> for the directory name. <code>${file}</code> for the file name. <code>${inputsUrl}</code> for the url of the inputs. All property names are case-sensitive. Do not use the built-in names for custom properties. Yes Hidden Properties (below) Deployment Base Path String The base location to store deployment results and backups for rollback. No Version Name String Version Name No Component Name String Component Name No Resource Id String Resource Id Yes"},{"location":"steps/#note","title":"Note:","text":"<ul> <li>Deployment Action filter is applicable only if Backup is enabled in Deploy Data Sets step</li> <li>Deployment Action filter is applicable only for loop types Sequential Datasets or PDS Members</li> <li>Target Dataset Name filter is applicable for only Dataset/PDS Member loop types</li> </ul>"},{"location":"steps/#remove-all-versions","title":"Remove All Versions","text":"<p>Remove all versions in an environment.</p> Name Type Description Required Dry Run Boolean Select to specify a dry run, which does not delete versions. Instead, the versions to be deleted are written to the output log for verification. No Days to Retain Versions Integer If set to greater than 0, version will be removed from inventory only if created more than this many days ago. No"},{"location":"steps/#remove-redundant-versions","title":"Remove Redundant Versions","text":"<p>Remove redundant versions in an environment. Redundant versions are versions that are completely replaced by subsequent versions.</p> Name Type Description Required Dry Run Boolean Select to specify a dry run, which does not delete versions. Instead, the versions to be deleted are written to the output log for verification. No Days to Retain Versions Integer If set to greater than 0, version will be removed from inventory only if created more than this many days ago. No"},{"location":"steps/#replace-tokens-mvs","title":"Replace Tokens MVS","text":"<p>Replace tokens in MVS data set using properties.</p> Name Type Description Required Allow Wildcard Boolean Select to use an asterisk (*) as a wildcard character in the Include Data Sets field. The asterisk matches any characters. Using wildcard characters can result in updates to a large number of data set members or unexpected updates. Yes End Token Delimiter String The end delimiter character to use for identifying tokens. No Exclude Data Sets String Specify a list of data set patterns to exclude from processing. Separate patterns with commas or newline characters. Use an asterisk (*) to match any characters. For example, USERID.JCL(ABC*) No Explicit Tokens String Specify a list of explicit tokens to replace, separated by newline characters. Use the following format: token-&gt;value. For example, mytoken-&gt;new_value will replace the mytoken string with new_value in all files. This field is not affected by the delimiter or prefix fields. To replace @token@ with new_value, specify @token@-&gt;new_value. If you specify a value in the Property List field, the explicit tokens are added as additional values to replace and override any properties that have the same name. Regular expressions are not supported. No Fail On Truncate Boolean Select to set the step to fail if the line exceeds the record length after replacement. If cleared, the line is truncated to fit the record length. No Include Data Sets String Specify a list of patterns that describe data sets to process. Separate patterns with commas or newline characters. For example, specify USERID.JCL(ABC) for a partitioned data set, or USERID.DATA for a sequential data set. Yes Property List String Specify a value here to use existing property names as tokens to replace in the target files. For example, specify <code>${p:environment/allProperties}</code> use the names of all component environment properties tokens and the property values as the replacements. Similarly, specify <code>${p:component/allProperties}</code>,<code>${p:environment/allProperties}</code> to use all component and component environment properties for token replacement. The delimiter and prefix settings above apply. For example, if the start and end token delimiters are the at sign (@) and property is called token1, then the step searches for @token1@ to replace. No Property Prefix String Specify a prefix to use to determine which properties are included in token replacement. Leave blank to use all properties. No Start Token Delimiter String The start delimiter character to use for identifying tokens. No"},{"location":"steps/#rollback-data-sets","title":"Rollback Data Sets","text":"<p>Rollback data sets and HFS files to a backup created in the previous deployment.</p> <p>NOTE: Uncheck Delete Backup Data check box in the Rollback step. Instead, add Cleanup Backup Files step as a last step in the rollback process design. To delete backup files from z/OS Unix system.</p> Name Type Description Required Check Access Boolean Select to check permission to update the data sets to deploy. No Delete Backup Data Boolean Select to remove the backup data that was created during deployment for this version. No HFS Target Directory String Specify a target directory to deploy HFS files. No Prevent Risky Rollback Enumeration: true/false/<code>${p?:prevent.risky.rollback}</code> Set to TRUE to prevent risky rollback. A risky rollback tries to rollback modules that have been replaced by a subsequent version. Yes Run to Check Risk Only Boolean Select to do a dry run which only checks for risky rollback. No actual rollback is done when doing a dry run. The step will fail when risk is detected, otherwise, the step will pass. No Hidden Properties (below) Deployment Base Path String The base location to store deployment results and backups for rollback. Yes Temporary DSN Prefix String Specify a DSN prefix to be used to create temporary data sets. The default value is the BUZ_TMP_DSN_PREFIX environment variable. If a value is not provided, the prefix in the agent user\u2019s profile or the agent user\u2019s ID is used. Prefix should not be more than 17 characters. No Environment Id String Environment Id Yes Version Name String Version Name Yes Version Id String Version Id Yes Version Type String Version Type Yes Component Name String Component Name Yes Resource Id String Resource Id Yes Component Id String Component Id Yes"},{"location":"steps/#run-mvs-command","title":"Run MVS Command","text":"<p>Run MVS system commands.</p> Name Type Description Required Fail Message String Specify messages that indicate command failure. The step fails if any of these messages are in the system responses. Separate multiple messages with newline characters. No MVS Commands String Specify a list, separated by newline characters, of MVS system commands to run. Yes Stop On Fail Boolean Select to stop running commands after a command fails. No"},{"location":"steps/#run-tso-or-ispf-command","title":"Run TSO or ISPF Command","text":"<p>Run TSO and ISPF commands using the ISPF gateway.</p> Name Type Description Required Command To Run String Specify the TSO and ISPF commands to run. Separate multiple commands with newline characters. Interactive TSO commands are not supported. Yes ISPF TSO Profile String Specify an existing ISPF profile to use in the call. No Run In A Reusable ISPF Session Boolean Select to run commands in a reusable ISPF session that stays active between calls. No Show Operation Log Boolean No Stop On Fail Boolean Select to stop running commands after a command fails with a non-zero return code. No TSO Or ISPF Enumeration: TSO/ISPF Only ISPF supports return code. Yes"},{"location":"steps/#submit-job","title":"Submit Job","text":"<p>Submit job.</p> <p>Note: * Using passphrase in place of password is supported from JMON version v2.9.14. Passphrase authentication is enabled by setting property PASS_PHRASE to ON in JMON configurations. JMON binaries with passphrase support are copied to #HLQ#.SBUZAUTH dataset from agent version 7.1.2.0 after agent install or upgrade. * When the JCL Line with replace tokens is 72 characters long, last character is assumed to be continuation character and this character is kept intact during token replacement and submitting Job. * When the JCL Line with replace tokens is 80 characters long, the 72nd character is assumed to be continuation character and the characters 73-80 are considered to be sequence numbers. In this case, the characters 72-80 are kept intact during token replacement and submitting job.</p> Name Type Description Required Default Job Statement String Default job statement to use if no job statement is found in the JCL. The job statement is not validated. Ensure that the job statement contains valid values for your system. Token replacement rules are not applied to the default job statement. No JCL String Enter the JCL to submit. No JCL Dataset String Submits JCL from a partitioned data set (PDS) member. Input can be a PDS member name: A.B.C(MEM). Or a PDS member pattern: A.B.C(D*X). Or a PDS name: A.B.C. When the input is a member pattern, all matching members are submitted. When the input is a PDS name, all members are submitted. Multiple JCL statements are submitted in sequence using the same settings. Multiple input JCL statements cannot be used together with Replace Token sets for Each Job field. No JCL File String Submits JCL in a file in the UNIX file system. For example, /u/userid/jobname.jcl No Max Lines String Specify the maximum number of lines to display in the log. Set it to -1 to display all the lines. No Max Return Code String Specify the maximum return code for the step. The step fails if the JCL return code is greater than the specified value. Yes Replace Token sets for Each Job String One job is submitted for each set of token replacement rules. Each set must be separated by a line containing only two forward slashes (//) characters. Within a set, each rule must be on a separate line. No Replace Tokens String Specify replacement rules to apply to the JCL before submission. Rules are represented by a list of explicit tokens to replace in the following format: token-&gt;value. Separate rules with newline characters. For example, mytoken-&gt;new_value will replace the mytoken string with new_value in all files. To replace @token@ with new_value, specify @token@-&gt;new_value. Regular expressions are not supported. No Show Output String Specify the output data set to be displayed in the log. Separate multiple data sets with commas. Specify ALL for all data sets. No Stop On Fail Boolean Select to stop submitting jobs after a job fails. Failure is determined by the Max Return Code and Timeout fields. A JCL error is always considered a failure. No Timeout String Specify the timeout in seconds. No Wait For Job Boolean Select to wait for the job to complete. If cleared, the Timeout, Show Output, Max Lines, and Max Return Code fields are not used. No Hidden Properties (below) Use Agent/Impersonation Id to submit Job Enumeration: TRUE/FALSE/<code>${p:jes.use.run.id}</code> Set it to TRUE to submit the job using the Agent Id (or) impersonation Id used to run this step. Set it to FALSE to submit the job with a specific UserId and password/passticket. Yes Host Name String Host Name or IP address to connect JMON Yes Job Monitor Port String JES job monitor port (1-65535). Default is 6715. Yes User Name String User Name No Password String Password No Use Passticket Boolean Use PassTicket authentication if a password is not provided. See the z/OS Utility plug-in documentation for the required configuration to allow PassTickets. No IRRRacf.jar File String Specify the full path to the System Access Facility (SAF) JAR file, which is IRRRacf.jar. The default value is /usr/include/java_classes/IRRRacf.jar. Yes IRRRacf Native Library Path String Specify the path to the System Access Facility (SAF) native library, which is libIRRRacf.so. There is one library for 31-bit Java and one for 64-bit Java. You must specify the path of the appropriate library based on the version of Java that you are running. The default value is /usr/lib. Yes Print job output of each job in separate page Boolean When mutliple jobs are submitted in a single plugin step, check this box to get each output in separate page. First page will be blank and output will start from second page No"},{"location":"steps/#wait-for-job","title":"Wait For Job","text":"<p>Wait for a submitted job to complete. Note: Using passphrase in place of password is supported from JMON version v2.9.14. Passphrase authentication is enabled by setting property PASS_PHRASE to ON in JMON configurations. JMON binaries with passphrase support are copied to #HLQ#.SBUZAUTH dataset from agent version 7.1.2.0 after agent install or upgrade.</p> Name Type Description Required Job ID String Specify the job ID. For example, JOB06663. Use the <code>${p:submitStepName/jobId}</code> property to refer to the job ID from an earlier Submit Job step. No Max Lines String Specify the maximum number of lines to display in the log. Set it to -1 to display all the lines. No Max Return Code String Specify the maximum return code for the step. The step fails if the JCL return code is greater than the specified value. Yes Show Output String Specify the output data sets to display in the log. Separate multiple data sets with commas. Specify ALL to display all data sets. No Timeout String Specify the timeout in seconds. No Hidden Properties (below) Use Agent/Impersonation Id to wait For Job Enumeration: TRUE/FALSE/<code>${p:jes.use.run.id}</code> Set it to TRUE to submit job using the Agent Id (or) impersonation Id used to run this step. Set it to FALSE to submit job with a specific UserId and password/passticket. Yes Host Name String Host Name or IP address to connect JMON Yes Job Monitor Port String JES job monitor port (1-65535). Default is 6715. Yes User Name String User Name No Password String Password No Use Passticket Boolean Use PassTicket authentication if a password is not provided. See the z/OS Utility plug-in documentation for the required configuration to allow PassTickets. No IRRRacf.jar File String Specify the full path to the System Access Facility (SAF) JAR file, which is IRRRacf.jar. The default value is /usr/include/java_classes/IRRRacf.jar. Yes IRRRacf Native Library Path String Specify the path to the System Access Facility (SAF) native library, which is libIRRRacf.so. There is one library for 31-bit Java and one for 64-bit Java. You must specify the path of the appropriate library based on the version of Java that you are running. The default value is /usr/lib. Yes"},{"location":"steps/#delete-dataset","title":"Delete Dataset","text":"<p>Deletes a dataset PDS or Sequential.</p> Name Type Description Required Dataset Name String Name of the datasets to be deleted. It can be a sequential dataset or PDS member or PDS. Separate dataset names with a newline. If the single quotation marks are omitted, the user's data set prefix from the TSO profile is automatically appended to the front of the dataset name. Wildcards are not allowed. GDGs with relative generation number are not allowed. Yes Members List String Specify members to be deleted from the only PDS mentioned in Datasets input. Separate member names with a newline. No"},{"location":"steps/#cleanup-backup-files","title":"Cleanup Backup Files","text":"<p>Delete backup files created during deploy datasets step.</p> <p>All the properties in the step are hidden properties</p> Name Type Description Required Deployment Base Path String The base location where deployment results and backups for rollback are stored. Yes Version Name String Name of the version Yes Component Name String Name of the component Yes Resource Id String Resource Id Yes"},{"location":"steps/#restore-backup-datasets","title":"Restore Backup Datasets","text":"<p>Restored datasets from backup taken during deployment</p> Name Type Description Required Restore Dataset Mapping String Specify list of mapping rules for the datasets to be restored, separated by newline characters. Use the following format: Env_Dataset,Restore_Dataset. Use the asterisk (*) in the Env_Dataset value to match any characters. If multiple rules specify the same Env_Dataset value, only the first one is used. Yes Allow Creating Dataset Boolean Select to create a dataset if the specified restore dataset does not exist. No Hidden Properties (below) ISPF Gateway Path String Specify the path for ISPF gateway binary files. Yes Deployment Base Path String The base location to store deployment results and backups for rollback. The default value is the BUZ_DEPLOY_BASE environment variable, which is set to the deployment base path that was specified during installation. Typically, you do not change this value. Yes Temporary DSN Prefix String Specify a DSN prefix to be used to create temporary data sets. The default value is the BUZ_TMP_DSN_PREFIX environment variable. If a value is not provided, the prefix in the agent user\u2019s profile or the agent user\u2019s ID is used. Prefix should not be more than 17 characters. No Version Name String Version Name Yes Component Name String Component Name Yes Resource Id String Resource Id Yes"},{"location":"troubleshooting/","title":"Troubleshooting","text":""},{"location":"troubleshooting/#copy-artifacts-step-limitation","title":"Copy Artifacts step limitation","text":"<p>When you use the Copy Artifacts step, you can copy only in the same logical partition (LPAR). To transfer artifacts between different LPARs, use the FTP Artifacts step.</p>"},{"location":"troubleshooting/#missing-return-code-for-run-tso-or-ispf-command-step","title":"Missing return code for Run TSO or ISPF Command step","text":"<p>If you use the Run TSO or ISPF Command step to run a TSO command, the return code might not be displayed in IBM UrbanCode Deploy because the ISPF gateway does not support passing return codes when in TSO mode. To work around this behavior, in the TSO Or ISPF list, select ISPF instead of TSO.</p>"},{"location":"troubleshooting/#repository-field-for-copy-artifacts-and-ftp-artifacts-steps","title":"Repository field for Copy Artifacts and FTP Artifacts steps","text":"<p>The local repository referred to in the Copy Artifacts and FTP Artifacts steps is not the Codestation repository, but rather the z/OS deployment tools artifact repository. You specify this directory when you install the z/OS deployment tools. By default, the artifact repository is the following directory: agent_installation_directory/var/repository. To learn more, see Completing the installation of the z/OS deployment tools.</p>"},{"location":"troubleshooting/#disable-inputs-for-z-inventory","title":"Disable inputs for Z Inventory","text":"<p>Follow below steps to disable inputs for Z Inventory.</p> <ul> <li>Upgrade the z/OS Utility plugin to latest version.</li> <li>Take a backup of <code>AGENT_HOME/bin/setenv-zos.sh</code> file</li> <li>Edit <code>AGENT_HOME/bin/setenv-zos.sh</code> file and add <code>ignore.zsearch.inputs</code> property in <code>ZOS_JAVA_OPTS</code> export command as below setting it to <code>true</code>.</li> </ul> <p><code>export ZOS_JAVA_OPTS='-Xmx128m -Dignore.zsearch.inputs=true'</code></p> <ul> <li>Restart the Agent for changes to be applied.</li> </ul> <p>Note: This will also fix APAR PH57385 - Error deploying version.Status code - 400</p>"},{"location":"usage/","title":"Usage","text":"<p>The following pages provide usage information about this plug-in:</p> <ul> <li>Deployment and Rollback for z/OS component version</li> <li>Deploy a component version to z/OS platform<ul> <li>Component process setup for deploying component version</li> <li>Application process setup for deploying component version</li> </ul> </li> <li>Rollback a component version from z/OS platform<ul> <li>Component process setup for rolling back a component version</li> <li>Application process setup for rolling back a component version</li> </ul> </li> <li>Rollback for z/OS component version with application template</li> <li>Deploying by using the Job Monitor</li> <li>Submitting a JCL job and then checking for status</li> <li>Submitting a JCL job from a template</li> <li>MVS component template</li> <li>Managing redundant versions</li> <li>Remove Redundant Versions</li> <li>Ignoring High Level Qualifiers</li> <li>Running MVS system commands</li> <li>Using custom properties in deployments</li> <li>Deploying data sets and running CICS commands</li> <li>Deploying HFS files</li> </ul>"},{"location":"usage/#running-mvs-system-commands","title":"Running MVS system commands","text":"<p>The Run MVS Command step uses the Java programming interface with the System Display and Search Facility (SDSF) to run MVS system commands on the agent. To use the Run MVS Command step, you must work with your system administrator to configure security properly for the agent user account. In the following examples, protecting resources by setting the universal access authority (UACC) to NONE might prevent all users, except users with explicit permission, from accessing the protected command.</p> <p>The agent user account must be authorized to use SDSF from Java and must be authorized to issue MVS slash (/) commands from SDSF. MVS commands are protected by defining a resource name in the SDSF class, as shown in the following table.</p> Resource name Class Access ISFOPER.SYSTEM SDSF READ <p>If the SDSF class is not activated yet, use following command to activate itfirst. SETROPTS CLASSACT(SDSF)</p> <p>To use the Resource Access Control Facility (RACF) to authorize the use of an MVS command, issue commands similar to the commands in the following examples: RDEFINE SDSF ISFOPER.SYSTEM UACC(NONE) PERMIT ISFOPER.SYSTEM CLASS(SDSF) ID(userid or groupid) ACCESS(READ)</p> <p>Additionally, the agent user account must be authorized to use the ULOG command to view command responses. MVS commands can return responses to the user console and to the user log (ULOG). The ULOG command is protected a resource in the SDSF class, as shown in the following table.</p> Resource name Class Access ISFCMD.ODSP.ULOG.jesx SDSF READ <p>To use the Resource Access Control Facility (RACF) to authorize the use of the ULOG command, issue commands similar to the commands in the following example. RDEFINE SDSF ISFCMD.ODSP.ULOG.UACC(NONE) PERMIT ISFCMD.ODSP.ULOG. CLASS(SDSF) ID(userid or groupid) ACCESS(READ)</p> <p>Run following command to make your changes to profiles effective. SETROPTS RACLIST(SDSF) REFRESH</p> <p>For more information on setting up SDSF security, see the documentation available at System Display and Search Facility.</p> <p>The following settings show an example of how to configure the Run MVS Command step.</p> <p></p>"},{"location":"usage/#using-custom-properties-in-deployments","title":"Using custom properties in deployments","text":"<p>You can add custom properties to data sets or to members when you create component versions. The custom properties can then be used by the Generate Artifact Information step to generate commands or other input that can be used by other subsequent steps in the process.</p> <p>Before you can use the Generate Artifact Information step, a component version must be deployed by using the Deploy Data Sets step.</p> <p>In the following example, a custom property is used to generate IBM DB2 database commands.</p> <p>The following shiplist file shows the DB2 plan name as a custom property to the DBRM data set:</p> <pre><code>&lt;manifest type=\"MANIFEST\\_SHIPLIST\"&gt;\n&lt;container name=\"TONY.MORT.DEV.LOAD\" type=\"PDS\" deployType=\"CICS\\_LOAD\"&gt;\n&lt;resource name=\"JKECMORT\" type=\"PDSMember\"/&gt;\n&lt;/container&gt;\n&lt;container name=\"TONY.MORT.DEV.DBRM\" type=\"PDS\" deployType=\"DBRM\"&gt;\n**&lt;property name=\"plan\" value=\"TONY\"/&gt;**\n&lt;resource name=\"\\*\" type=\"PDSMember\"/&gt;\n&lt;/container&gt;\n&lt;/manifest&gt;\n</code></pre> <p>When you create a component version by using this shiplist file, the custom property is visible in the version artifacts view. Properties added to a data set are also visible to all members of the data set.</p> <p></p> <p>In the following deployment process, the FTP Artifacts and Deploy Data Sets steps deploy the members to the target system. The Generate Artifact Information step generates TSO commands that are then used to run the REXX BIND commands. The generated commands contain the DB2 plan name from the custom property. The generated commands are then run by the Run TSO or ISPF Command.</p> <p></p> <p>The Generate Artifact Information step uses the following settings:</p> <p></p> <p>Use <code>${*propertyName*}</code> to refer to a custom property. In the previous example, TEST.REXX(BIND) is a REXX script that accepts plan, library, and member values as parameters and then runs the DB2 DSN BIND command.</p> <p>The Generate Artifact Information step generates the following output properties. In this example, the text property contains the generated TSO commands.</p> <p></p> <p>In this example, the Run TSO or ISPF Command step uses the following settings:</p> <p></p>"},{"location":"usage/#deploying-data-sets-and-running-cics-commands","title":"Deploying data sets and running CICS commands","text":""},{"location":"usage/#example-deploying-data-sets-and-running-cics-commands","title":"Example: Deploying data sets and running CICS commands","text":"<p>In this process example, the z/OS data sets must be in the component. Also, the environment contains agents that are running z/OS. In addition to the z/OS Utility plug-in, the CICS TS plug-in must be installed. The process runs the following steps in order:</p> <ol> <li>The Copy Artifacts step loads the artifacts that make up the z/OS component version.</li> <li>The Deploy Data Sets step deploys the component version to z/OS.</li> <li>The Generate Artifact Information step generates a list of CICS members.</li> <li>The NEWCOPY Programs step, in the CICS TS plug-in, runs the NEWCOPY command on the members.</li> </ol> <p></p> <p>In this example, the Generate Artifact Information step is configured with the following properties:</p> <p></p> <p>The output of the Generate Artifact Information step looks similar to the following properties:</p> <p></p> <p>In this example, the NEWCOPY Programs step is configured with the following properties:</p> <p></p> <p>The execution log of the NEWCOPY Programs step looks similar to the following output:</p> <pre><code>PerformNEWCOPY:\n\nInfo:NEWCOPY \"JKEMLIST\" succeeded.\n\nInfo:NEWCOPY \"JKEMORT\" succeeded.\n\nInfo:NEWCOPY \"JKEBXXC2\" succeeded.\n\nInfo:NEWCOPY \"JKEBXXS1\" succeeded.\n\nInfo:NEWCOPY \"JKECSMRD\" succeeded.\n\nInfo:NEWCOPY \"JKMXXGB\" succeeded.\n\nInfo:NEWCOPY \"JKEMLIS\" succeeded.\n\nInfo:NEWCOPY \"JKECSMRT\" succeeded.\n\nInfo:NEWCOPY \"JKMXXGA\" succeeded.\n\nInfo:NEWCOPY \"JKECMAIN\" succeeded.\n\nInfo:NEWCOPY \"JKEBXXC1\" succeeded.\n\nInfo:NEWCOPY \"JKEMLISD\" succeeded.\n\nInfo:NEWCOPY \"JKEMPMT\" succeeded.\n\nInfo:NEWCOPY \"JKECMORT\" succeeded.\n\nInfo:NEWCOPY \"JKEMAIN\" succeeded.\n\nSummary:15 NEWCOPY request(s) succeeded, 0 NEWCOPY request(s) failed.\n</code></pre>"},{"location":"usage/#submitting-jcl-jobs-from-a-template","title":"Submitting JCL jobs from a template","text":"<p>To submit a JCL job from a template, use the Submit Job step, and then set up the step properties similar to the following example:</p> <p></p> <p>To submit multiple jobs from the same template, specify multiple sets of rules in the Replace Tokens For Each Job field. Separate rule sets with a new line that contains only two forward slashes (//). The status of the Submit Job step is success if all of the jobs run to completion, and fail if any of the jobs fail. Multiple jobs run in sequence, and use the same settings for job output and status checking. If you select Stop On Fail, no subsequent jobs are run after a job fails. To submit multiple jobs that check the existence of multiple data set members, set up the step properties similar to the following example:</p> <p></p> <p>In the previous example, three jobs are submitted because three rule sets are specified in the Replace Tokens For Each Job field. The three jobs check the JKEMPMT, JKECMORT, and JKEMLIST members in that order. The rules that are specified in the Replace Tokens field are used for all jobs. Because Stop On Fail is selected, if any job fails no subsequent jobs are submitted. Finally, the Max Return Code field is set to 0 so that any return code greater than 0 is considered a job failure. For example, a return code of 4 from the LISTDS command, which indicates that a member name was not found, is considered a job failure.</p>"},{"location":"usage/#processing-multiple-data-sets-or-data-set-members","title":"Processing multiple data sets or data set members","text":"<p>Use the Generate Artifact Information step to process each data set or data set member in a version. In the following example, the process verifies that data set members are deployed.</p> <p></p> <p>The Generate Artifact Information step uses the following settings:</p> <p></p> <p>The Submit Job step uses the following settings:</p> <p></p>"},{"location":"usage/#deploying-hfs-files","title":"Deploying HFS files","text":"<p>A component version of HFS files can be deployed in either old format or new format of HFS directory mapping. In the old format of HFS directory mapping, it accepts only the target directory as input and during deployment, the container directories are created, and files are moved to the respective container. Mapping is in the below format<code>Target-Directory-path</code>Whereas the new format of HFS directory mapping, follows the same rule as for deploying the MVS Datasets. The mapping may contain multiple lines with each line in the below format <code>Source-Container-Name, Target-Directory-path</code></p> <p>On contrary to old format the deployment with new format does not create a sub-directory of source container while moving to target directory.</p>"},{"location":"usage/#deploying-by-using-the-job-monitor","title":"Deploying by using the Job Monitor","text":"<p>Refer Deploying by using the Job Monitor for more details</p>"},{"location":"usage/#managing-redundant-versions","title":"Managing redundant versions","text":"<p>Redundant versions are incremental versions that are replaced by one or more subsequent incremental versions. In the following example, when Version 2 is deployed Version 1 becomes a redundant version, because all artifacts that are deployed with Version 1 are replaced by Version 2.</p> <p></p>"},{"location":"usage/#remove-redundant-versions","title":"Remove Redundant Versions","text":"<p>The Remove Redundant Versions plug-in step removes redundant versions from the inventory. On zOS USS, it deletes the redundant version's directory and its contents that was created when the version was deployed.</p>"},{"location":"usage/#snapshots","title":"Snapshots","text":"<p>Redundant versions are excluded when you create a snapshot. This exclusion prevents unnecessary promotion of incremental versions to subsequent environments. To include redundant versions in a snapshot, edit the snapshot to add the redundant versions.</p>"},{"location":"usage/#ignoring-high-level-qualifiers","title":"Ignoring High-level qualifiers","text":"<p>Set the High Level Qualifier Length value in the component configuration to ignore high-level qualifiers during redundant version calculations and risky rollback checking.</p> <p>For example, For a z/OS component version lets assume datasets are created as BUILD.DEV.REL100.COBOL, the third qualifier REL100 changes for every new release. For redundant versions calculation and prevent risky rollback, set High Level Qualifier Length value to 3. This is to ignore the first 3 High level qualifiers of the dataset.</p>"},{"location":"usage/#mvs-component-template","title":"MVS component template","text":"<p>The z/OS Utility plug-in includes the MVSTEMPLATE component template. The template contains default processes, which can be used directly. The template also lists the component properties and environment properties that that must be set to run z/OS deployments.</p>"},{"location":"usage/#default-processes","title":"Default processes","text":"Step Description Deploy Deploy data sets. Version artifacts are fetched from the CodeStation repository on the z/OS system. Deploy get artifacts using FTP Deploy data sets. Version artifacts are fetched from the Codestation repository by using FTP. Remove all versions Remove all versions in an environment, including the backup created during version deployment. Use this process to start a new round of development with a clean environment. Audit history is available even if versions were removed from the environment. Remove redundant versions Remove redundant versions in an environment. Redundant versions are versions that are replaced completely by versions that are deployed later. Remove redundant versions with manual verification Remove redundant versions in an environment. Redundant versions are versions that are replaced completely by versions that are deployed later. Sample JCL submission process Model JCL submission on the two types of usage in this sample. Uninstall Uninstall a version and restore the backup data sets."},{"location":"usage/#component-properties","title":"Component properties","text":"Name Required Description ucd.repository.location true The location of the repository where the z/OS deployment tools store artifacts. ucd.repository.host false Host name of the FTP server from which to get version artifacts. ucd.repository.user false FTP user name. ucd.repository.password false FTP password"},{"location":"usage/#environment-properties","title":"Environment properties","text":"Name Required Description deploy.env.pds.mapping true The PDS packages, and the locations to deploy them in the restore mapping table. Each line is a mapping rule with the format of From PDS,To PDS. The value can be over-ridden by a property with higher order of precedence: for example, an agent property or resource property. jes.host false Host name of the job server. Use localhost unless you need to submit the job to another z/OS system. jes.user false User ID for the JES subsystem. jes.password false Password for the JES subsystem. jes.monitor.port false JES Job Monitor port (1-65535). The default port is 6715. BUZ_DEPLOY_BASE false The base location to store deployment results and backups for rollback. Each agent provides a default value. If multiple environments use the same agent, this value can be over-ridden by a property with higher order of precedence: for example, an agent property or resource property."},{"location":"usage/#submitting-a-jcl-job-and-then-checking-for-status","title":"Submitting a JCL job and then checking for status","text":""},{"location":"usage/#example-submitting-a-jcl-job-and-then-checking-for-status","title":"Example: Submitting a JCL job and then checking for status","text":"<p>The process runs the following steps in order:</p> <ol> <li>The Submit Job step starts the JCL job.</li> <li>The Shell step represents other processing steps to take while the JCL job runs.</li> <li>The Wait For Job step stops processing until the JCL job completes.</li> </ol> <p></p>"},{"location":"usage-pages/deploy-rollback/","title":"Deployment and Rollback for z/OS component version","text":""},{"location":"usage-pages/deploy-rollback/#this-page-covers-below-sections","title":"This page covers below sections","text":"<ul> <li>Deploy a component version to z/OS platform</li> <li>Component process setup for deploying component version</li> <li>Application process setup for deploying component version</li> <li>Rollback a component version from z/OS platform</li> <li>Component process setup for rolling back a component version</li> <li>Application process setup for rolling back a component version</li> </ul>"},{"location":"usage-pages/deploy-rollback/#deploy-a-component-version-to-zos-platform","title":"Deploy a component version to z/OS platform","text":""},{"location":"usage-pages/deploy-rollback/#component-process-setup-for-deploying-component-version","title":"Component process setup for deploying component version","text":"<p>For zOS deployment, create a component process with Process Type as Deployment.</p> <p>Following steps are mandatory for deploying a zOS Component version stored on UrbanCode Deploy codestation.</p> <ul> <li>Download Artifacts for zOS step to download the version artifacts</li> <li>Deploy Data sets step to deploy datasets to mapped target Dataset/HFS Directory</li> </ul> <p>Component process design will be as below.</p> <p></p> <p>Post-processing steps can be added as per the requirement after Deploy Data sets step with below steps</p> <ul> <li>Generate Artifact Information step to generate text based on the passed template.</li> <li>Submit Job step to run DB2 Bind job</li> <li>Replace Token MVS step to replace tokens in dataset/member</li> <li>CICS New Copy step and so on.</li> </ul> <p>If external repository (Artifactory or Nexus) is used to store zOS Component version, Use Download Artifacts for zOS External Repo step to download version artifacts from the external repository. Component process design will be as below.</p> <p></p>"},{"location":"usage-pages/deploy-rollback/#application-process-setup-for-deploying-component-version","title":"Application process setup for deploying component version","text":"<p>For deployment, create an application process with Inventory Management set to Automatic under process configurations. A sample application process contains Install Component step which internally calls the component process for deployment contains Deploy Data sets step.</p> <p>Application process design will be as below.</p> <p></p>"},{"location":"usage-pages/deploy-rollback/#rollback-a-component-version-from-zos-platform","title":"Rollback a component version from z/OS platform","text":""},{"location":"usage-pages/deploy-rollback/#component-process-setup-for-rolling-back-a-component-version","title":"Component process setup for rolling back a component version","text":"<p>For rollback, create a component process with Process Type as Uninstall. A sample component process design starts with Rollback Data sets step and ends with Cleanup Backup Files step.</p> <p>Post-processing steps can be added as per the requirements after Rollback data sets step with below steps</p> <ul> <li>Generate Artifact Information step to generate text based on the passed template.</li> <li>Submit Job step to run DB2 Bind job</li> <li>CICS New Copy step and so on.</li> </ul> <p>Component process design will be as below.</p> <p></p>"},{"location":"usage-pages/deploy-rollback/#application-process-setup-for-rolling-back-a-component-version","title":"Application process setup for rolling back a component version","text":"<p>For rollbacks, an application process is created with Inventory Management set to Advanced under process configurations. A sample application process contains two steps.</p> <ul> <li>Run Process For Each Version step</li> <li>Component Inventory Update step</li> </ul> <p>In Run Process For Each Version step point to the component process created for rollback. Component Inventory Update step must be the last step in the application process design with below settings</p> <ol> <li>Select component</li> <li>Set Action to Remove Desired Inventory</li> <li>Set For Which Versions? to All selected (Manual uninstall)</li> <li>Status is kept Active</li> </ol> <p>Application process design will be as below.</p> <p></p> Back to ... Usage"},{"location":"usage-pages/rollback-with-template/","title":"Rollback for z/OS component version with application template","text":""},{"location":"usage-pages/rollback-with-template/#this-page-covers-below-sections","title":"This page covers below sections","text":"<ul> <li>Rollback for z/OS component version with application template</li> <li>This page covers below sections<ul> <li>Overview</li> <li>Component Process for Uninstall</li> <li>Application Template Process for Uninstall</li> <li>Component Process for Rollback</li> <li>Application Template Process for Rollback</li> <li>Execution</li> </ul> </li> </ul>"},{"location":"usage-pages/rollback-with-template/#overview","title":"Overview","text":"<p>When designing application process with application template below two differences are observed</p> <ul> <li>Application process steps like Install Multiple component and Uninstall multiple components works with component tag instead of component name.</li> <li>Application process inside an application template has automatic inventory management and cannot be managed manually.</li> </ul> <p>To overcome above differences below changes are needed</p> <ul> <li>Add a component tag to z/OS component(s)</li> <li>Create two component processes under z/OS component (or) component template and two application processes for z/OS Artifacts Rollback. One to run as an operational process and other to run as an uninstall process to remove the version from inventory as shown below</li> </ul>"},{"location":"usage-pages/rollback-with-template/#component-process-for-uninstall","title":"Component Process for Uninstall","text":"<ul> <li>Create a component process with type uninstall and add a set status step to success as below.</li> </ul> <p>This is a dummy step to uninstall the version from the inventory after all the steps of Rollback process is completed successfully.</p>"},{"location":"usage-pages/rollback-with-template/#application-template-process-for-uninstall","title":"Application Template Process for Uninstall","text":"<ul> <li>Create a new process in the application template. Add Uninstall Multiple Components step. Update below</li> <li>Add name for process step for e.g., \"Remove version from inventory\"</li> <li>Add component tag which has the component process</li> <li>Add component process name which has set status step</li> <li>Set Uninstall Type to All Selected For Process</li> </ul>"},{"location":"usage-pages/rollback-with-template/#component-process-for-rollback","title":"Component Process for Rollback","text":"<p>Create a component process with type operational (With version) and add all the steps of a typical rollback process like below</p> <ul> <li>Rollback Data Sets step</li> <li>Generate artifact step, Bind step, CICS step etc.,</li> <li>Cleanup backup files step</li> <li>Run Application process step</li> </ul> <p></p> <p>The Run Application process step should point to the uninstall application process and all other values should be UCD properties like below</p> <p></p>"},{"location":"usage-pages/rollback-with-template/#application-template-process-for-rollback","title":"Application Template Process for Rollback","text":"<p>Create a new process in the application template. Add Uninstall Multiple Components step and update below</p> <ul> <li>Add name for process step</li> <li>Add component tag which has the component process</li> <li>Add component process name which has rollback steps</li> <li>Set Uninstall Type to All Selected For Process</li> </ul>"},{"location":"usage-pages/rollback-with-template/#execution","title":"Execution","text":"<p>To rollback Z Artifacts, run Rollback Z Artifacts process to run all the rollback steps under component process. The Component process triggers Remove Version From Inventory process only when artifacts are rolled back and all the steps ran successfully.</p> Back to ... Usage"}]}